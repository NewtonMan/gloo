// Code generated by skv2. DO NOT EDIT.

package ratelimit_resource_handler

import (
	"context"
	"sort"

	"github.com/ghodss/yaml"
	"github.com/rotisserie/eris"
	"go.uber.org/zap"

	"github.com/solo-io/go-utils/contextutils"
	skv2v1 "github.com/solo-io/skv2/pkg/api/core.skv2.solo.io/v1"
	ratelimit_solo_io_v1alpha1 "github.com/solo-io/solo-apis/pkg/api/ratelimit.solo.io/v1alpha1"
	rpc_v1 "github.com/solo-io/solo-projects/projects/apiserver/pkg/api/fed.rpc/v1"
	"github.com/solo-io/solo-projects/projects/apiserver/server/apiserverutils"
	fedv1 "github.com/solo-io/solo-projects/projects/gloo-fed/pkg/api/fed.solo.io/v1"
	"k8s.io/apimachinery/pkg/types"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

func NewRatelimitResourceHandler(
	instanceClient fedv1.GlooInstanceClient,
	mcRatelimitCRDClientset ratelimit_solo_io_v1alpha1.MulticlusterClientset,

) rpc_v1.RatelimitResourceApiServer {
	return &ratelimitResourceHandler{
		instanceClient:          instanceClient,
		mcRatelimitCRDClientset: mcRatelimitCRDClientset,
	}
}

type ratelimitResourceHandler struct {
	instanceClient          fedv1.GlooInstanceClient
	mcRatelimitCRDClientset ratelimit_solo_io_v1alpha1.MulticlusterClientset
}

func (k *ratelimitResourceHandler) ListRateLimitConfigs(ctx context.Context, request *rpc_v1.ListRateLimitConfigsRequest) (*rpc_v1.ListRateLimitConfigsResponse, error) {

	var rpcRateLimitConfigs []*rpc_v1.RateLimitConfig
	if request.GetGlooInstanceRef() == nil || request.GetGlooInstanceRef().GetName() == "" || request.GetGlooInstanceRef().GetNamespace() == "" {
		// List rateLimitConfigs across all ratelimit instances
		instanceList, err := k.instanceClient.ListGlooInstance(ctx)
		if err != nil {
			wrapped := eris.Wrapf(err, "Failed to list gloo instances")
			contextutils.LoggerFrom(ctx).Errorw(wrapped.Error(), zap.Error(err), zap.Any("request", request))
			return nil, wrapped
		}
		for _, ratelimitInstance := range instanceList.Items {
			rpcRateLimitConfigList, err := k.listRateLimitConfigsForGlooInstance(ctx, &ratelimitInstance)
			if err != nil {
				wrapped := eris.Wrapf(err, "Failed to get ratelimit instance %s.%s", ratelimitInstance.GetNamespace(), ratelimitInstance.GetName())
				contextutils.LoggerFrom(ctx).Errorw(wrapped.Error(), zap.Error(err), zap.Any("request", request))
				return nil, wrapped
			}
			rpcRateLimitConfigs = append(rpcRateLimitConfigs, rpcRateLimitConfigList...)
		}
	} else {
		// List rateLimitConfigs for a specific gloo instance
		ratelimitInstance, err := k.instanceClient.GetGlooInstance(ctx, types.NamespacedName{
			Name:      request.GetGlooInstanceRef().GetName(),
			Namespace: request.GetGlooInstanceRef().GetNamespace(),
		})
		if err != nil {
			wrapped := eris.Wrapf(err, "Failed to get ratelimit instance %s.%s", ratelimitInstance.GetNamespace(), ratelimitInstance.GetName())
			contextutils.LoggerFrom(ctx).Errorw(wrapped.Error(), zap.Error(err), zap.Any("request", request))
			return nil, wrapped
		}
		rpcRateLimitConfigs, err = k.listRateLimitConfigsForGlooInstance(ctx, ratelimitInstance)
		if err != nil {
			wrapped := eris.Wrapf(err, "Failed to list rateLimitConfigs for ratelimit instance %s.%s", ratelimitInstance.GetNamespace(), ratelimitInstance.GetName())
			contextutils.LoggerFrom(ctx).Errorw(wrapped.Error(), zap.Error(err), zap.Any("request", request))
			return nil, wrapped
		}
	}

	return &rpc_v1.ListRateLimitConfigsResponse{
		RateLimitConfigs: rpcRateLimitConfigs,
	}, nil
}

func (k *ratelimitResourceHandler) listRateLimitConfigsForGlooInstance(ctx context.Context, instance *fedv1.GlooInstance) ([]*rpc_v1.RateLimitConfig, error) {

	ratelimitCRDClientset, err := k.mcRatelimitCRDClientset.Cluster(instance.Spec.GetCluster())
	if err != nil {
		return nil, err
	}
	usClient := ratelimitCRDClientset.RateLimitConfigs()

	var ratelimitRateLimitConfigList []*ratelimit_solo_io_v1alpha1.RateLimitConfig
	watchedNamespaces := instance.Spec.GetControlPlane().GetWatchedNamespaces()
	if len(watchedNamespaces) != 0 {
		for _, ns := range watchedNamespaces {
			list, err := usClient.ListRateLimitConfig(ctx, client.InNamespace(ns))
			if err != nil {
				return nil, err
			}
			for i, _ := range list.Items {
				ratelimitRateLimitConfigList = append(ratelimitRateLimitConfigList, &list.Items[i])
			}
		}
	} else {
		list, err := usClient.ListRateLimitConfig(ctx)
		if err != nil {
			return nil, err
		}
		for i, _ := range list.Items {
			ratelimitRateLimitConfigList = append(ratelimitRateLimitConfigList, &list.Items[i])
		}
	}
	sort.Slice(ratelimitRateLimitConfigList, func(i, j int) bool {
		x := ratelimitRateLimitConfigList[i]
		y := ratelimitRateLimitConfigList[j]
		return x.GetNamespace()+x.GetName() < y.GetNamespace()+y.GetName()
	})

	var rpcRateLimitConfigs []*rpc_v1.RateLimitConfig
	for _, rateLimitConfig := range ratelimitRateLimitConfigList {
		rpcRateLimitConfigs = append(rpcRateLimitConfigs, BuildRpcRateLimitConfig(rateLimitConfig, &skv2v1.ObjectRef{
			Name:      instance.GetName(),
			Namespace: instance.GetNamespace(),
		}, instance.Spec.GetCluster()))
	}
	return rpcRateLimitConfigs, nil
}

func BuildRpcRateLimitConfig(rateLimitConfig *ratelimit_solo_io_v1alpha1.RateLimitConfig, glooInstance *skv2v1.ObjectRef, cluster string) *rpc_v1.RateLimitConfig {
	m := &rpc_v1.RateLimitConfig{
		Metadata:     apiserverutils.ToMetadata(rateLimitConfig.ObjectMeta),
		GlooInstance: glooInstance,
		Spec:         &rateLimitConfig.Spec,
		Status:       &rateLimitConfig.Status,
	}
	m.Metadata.ClusterName = cluster
	return m
}

func (k *ratelimitResourceHandler) GetRateLimitConfigYaml(ctx context.Context, request *rpc_v1.GetRateLimitConfigYamlRequest) (*rpc_v1.GetRateLimitConfigYamlResponse, error) {
	ratelimitClientSet, err := k.mcRatelimitCRDClientset.Cluster(request.GetRateLimitConfigRef().GetClusterName())
	if err != nil {
		wrapped := eris.Wrapf(err, "Failed to get ratelimit client set")
		contextutils.LoggerFrom(ctx).Errorw(wrapped.Error(), zap.Error(err), zap.Any("request", request))
		return nil, wrapped
	}
	rateLimitConfig, err := ratelimitClientSet.RateLimitConfigs().GetRateLimitConfig(ctx, client.ObjectKey{
		Namespace: request.GetRateLimitConfigRef().GetNamespace(),
		Name:      request.GetRateLimitConfigRef().GetName(),
	})
	if err != nil {
		wrapped := eris.Wrapf(err, "Failed to get rateLimitConfig")
		contextutils.LoggerFrom(ctx).Errorw(wrapped.Error(), zap.Error(err), zap.Any("request", request))
		return nil, wrapped
	}
	content, err := yaml.Marshal(rateLimitConfig)
	if err != nil {
		wrapped := eris.Wrapf(err, "Failed to marshal kube resource into yaml")
		contextutils.LoggerFrom(ctx).Errorw(wrapped.Error(), zap.Error(err), zap.Any("request", request))
		return nil, wrapped
	}
	return &rpc_v1.GetRateLimitConfigYamlResponse{
		YamlData: &rpc_v1.ResourceYaml{
			Yaml: string(content),
		},
	}, nil
}
