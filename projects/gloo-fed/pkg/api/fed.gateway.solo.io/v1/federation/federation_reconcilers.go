// Code generated by skv2. DO NOT EDIT.

// Definition for federated resource reconciler templates.
package federation

import (
	"context"

	"github.com/hashicorp/go-multierror"
	"github.com/solo-io/go-utils/contextutils"
	"github.com/solo-io/go-utils/stringutils"
	"github.com/solo-io/skv2/pkg/reconcile"
	gateway_solo_io_v1 "github.com/solo-io/solo-apis/pkg/api/gateway.solo.io/v1"
	gateway_solo_io_v1_sets "github.com/solo-io/solo-apis/pkg/api/gateway.solo.io/v1/sets"
	fed_gateway_solo_io_v1 "github.com/solo-io/solo-projects/projects/gloo-fed/pkg/api/fed.gateway.solo.io/v1"
	"github.com/solo-io/solo-projects/projects/gloo-fed/pkg/api/fed.gateway.solo.io/v1/controller"
	mc_types "github.com/solo-io/solo-projects/projects/gloo-fed/pkg/api/fed.solo.io/core/v1"
	"github.com/solo-io/solo-projects/projects/gloo-fed/pkg/federation"
	"github.com/solo-io/solo-projects/projects/gloo-fed/pkg/federation/placement"
	"github.com/solo-io/solo-projects/projects/gloo-fed/pkg/multicluster"
	"go.uber.org/zap"
	"k8s.io/apimachinery/pkg/api/errors"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"sigs.k8s.io/controller-runtime/pkg/client"
)

type federatedGatewayReconciler struct {
	ctx               context.Context
	federatedGateways fed_gateway_solo_io_v1.FederatedGatewayClient
	baseClients       gateway_solo_io_v1.MulticlusterClientset
	placementManager  placement.Manager
	clusterSet        multicluster.ClusterSet
}

func NewFederatedGatewayReconciler(
	ctx context.Context,
	federatedGateways fed_gateway_solo_io_v1.FederatedGatewayClient,
	baseClients gateway_solo_io_v1.MulticlusterClientset,
	placementManager placement.Manager,
	clusterSet multicluster.ClusterSet,
) controller.FederatedGatewayFinalizer {
	return &federatedGatewayReconciler{
		ctx:               ctx,
		federatedGateways: federatedGateways,
		baseClients:       baseClients,
		placementManager:  placementManager,
		clusterSet:        clusterSet,
	}
}

func (f *federatedGatewayReconciler) ReconcileFederatedGateway(obj *fed_gateway_solo_io_v1.FederatedGateway) (reconcile.Result, error) {
	currentPlacementStatus := f.placementManager.GetPlacementStatus(&obj.Status)
	needsReconcile := obj.NeedsReconcile(currentPlacementStatus)
	allClusters := f.clusterSet.ListClusters()
	contextutils.LoggerFrom(f.ctx).Debugw("ReconcileFederatedGateway", zap.Any("FederatedGateway", obj), zap.Any("needsReconcile", needsReconcile),
		zap.Any("allClusters", allClusters))

	if !needsReconcile {
		return reconcile.Result{}, nil
	}

	statusBuilder := f.placementManager.GetBuilder()

	// Validate resource
	if obj.Spec.GetPlacement() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.PlacementMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedGateways.UpdateFederatedGatewayStatus(f.ctx, obj)
	}
	for _, cluster := range obj.Spec.Placement.GetClusters() {
		if !stringutils.ContainsString(cluster, allClusters) {
			updatedPlacementStatus := statusBuilder.
				UpdateUnprocessed(currentPlacementStatus, placement.ClusterNotRegistered(cluster), mc_types.PlacementStatus_INVALID).
				Eject(obj.GetGeneration())
			f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
			return reconcile.Result{}, f.federatedGateways.UpdateFederatedGatewayStatus(f.ctx, obj)
		}
	}
	if obj.Spec.Template.GetSpec() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.SpecTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedGateways.UpdateFederatedGatewayStatus(f.ctx, obj)
	}
	if obj.Spec.Template.GetMetadata() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.MetaTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedGateways.UpdateFederatedGatewayStatus(f.ctx, obj)
	}

	// ownerLabel is used to reference Federated resources via their children.
	ownerLabel := federation.GetOwnerLabel(obj)
	// since ownerLabel may be truncated (max length 63), we also store the full value in an annotation
	// for verification in case of collisions
	ownerAnnotation := federation.GetOwnerAnnotation(obj)

	spec := obj.Spec.Template.GetSpec()
	meta := obj.Spec.Template.GetMetadata()
	labels := federation.Merge(meta.GetLabels(), ownerLabel)
	annotations := federation.Merge(meta.GetAnnotations(), ownerAnnotation)

	multiErr := &multierror.Error{}
	for _, cluster := range allClusters {
		clusterGateways := gateway_solo_io_v1_sets.NewGatewaySet()
		if stringutils.ContainsString(cluster, obj.Spec.Placement.GetClusters()) {
			for _, namespace := range obj.Spec.Placement.GetNamespaces() {

				clusterGateways.Insert(&gateway_solo_io_v1.Gateway{
					ObjectMeta: metav1.ObjectMeta{
						Namespace:   namespace,
						Name:        meta.GetName(),
						Labels:      labels,
						Annotations: annotations,
					},
					Spec: *spec,
				})
			}
		}

		if err := f.ensureCluster(cluster, statusBuilder, clusterGateways, obj); err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
		}
	}

	f.placementManager.SetPlacementStatus(&obj.Status, statusBuilder.Build(obj.GetGeneration()))
	err := f.federatedGateways.UpdateFederatedGatewayStatus(f.ctx, obj)
	if err != nil {
		multiErr.Errors = append(multiErr.Errors, err)
		contextutils.LoggerFrom(f.ctx).Errorw("Failed to update status on federated gateway", zap.Error(err))
	}

	return reconcile.Result{}, multiErr.ErrorOrNil()
}

func (f *federatedGatewayReconciler) FederatedGatewayFinalizerName() string {
	return federation.HubFinalizer
}

func (f *federatedGatewayReconciler) FinalizeFederatedGateway(obj *fed_gateway_solo_io_v1.FederatedGateway) error {
	return f.deleteAll(obj)
}

// ensureCluster upserts all desired resources on the given cluster.
// An error is returned only if a retry is expected to resolve the issue.
func (f *federatedGatewayReconciler) ensureCluster(cluster string, statusBuilder placement.StatusBuilder, desired gateway_solo_io_v1_sets.GatewaySet, fedResource *fed_gateway_solo_io_v1.FederatedGateway) error {
	clientset, err := f.baseClients.Cluster(cluster)
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to get clientset", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToCreateClientForCluster(cluster),
		})
		return err
	}

	gatewayClient := clientset.Gateways()

	ownerLabel := federation.GetOwnerLabel(fedResource)
	existingList, err := gatewayClient.ListGateway(f.ctx, client.MatchingLabels(ownerLabel))
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to list Gateways", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToListResource("gateway", cluster),
		})
		return err
	}

	existing := gateway_solo_io_v1_sets.NewGatewaySet()
	for _, gateway := range existingList.Items {
		// double-check that this Gateway is actually owned by this FederatedGateway
		if !f.verifyOwner(fedResource, gateway) {
			continue
		}
		gatewayPointer := gateway
		existing.Insert(&gatewayPointer)
	}

	multiErr := &multierror.Error{}
	for _, desiredGateway := range desired.List() {
		err := gatewayClient.UpsertGateway(f.ctx, desiredGateway)
		if err != nil && errors.IsConflict(err) {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert gateway due to resource conflict", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResourceDueToConflict("gateway"),
			})
		} else if err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert gateway", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResource("gateway"),
			})
		} else {
			statusBuilder.AddDestination(cluster, desiredGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State: mc_types.PlacementStatus_PLACED,
			})
		}
	}

	for _, staleGateway := range existing.Difference(desired).List() {
		err := gatewayClient.DeleteGateway(f.ctx, client.ObjectKey{
			Namespace: staleGateway.Namespace,
			Name:      staleGateway.Name,
		})
		if client.IgnoreNotFound(err) != nil {
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to delete gateway", zap.Error(err))
			statusBuilder.AddDestination(cluster, staleGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_STALE,
				Message: placement.FailedToDeleteResource("gateway"),
			})
		}
	}

	return multiErr.ErrorOrNil()
}

// Delete all Gateways managed by the given FederatedGateway on all clusters.
// Used to ensure that Gateways generated by a FederatedGateway are cleaned up on delete.
func (f *federatedGatewayReconciler) deleteAll(fedResource *fed_gateway_solo_io_v1.FederatedGateway) error {
	ownerLabel := federation.GetOwnerLabel(fedResource)
	for _, cluster := range f.clusterSet.ListClusters() {
		clusterClient, err := f.baseClients.Cluster(cluster)
		if err != nil {
			return err
		}
		// TODO this requires permissions in all namespaces, we could restrict to to namespaces referenced by gloo instances
		list, err := clusterClient.Gateways().ListGateway(f.ctx, client.MatchingLabels(ownerLabel))
		if err != nil {
			return err
		}

		for _, gateway := range list.Items {
			// double-check that this Gateway is actually owned by this FederatedGateway
			if !f.verifyOwner(fedResource, gateway) {
				continue
			}
			err = clusterClient.Gateways().DeleteGateway(f.ctx, client.ObjectKey{
				Namespace: gateway.Namespace,
				Name:      gateway.Name,
			})
			if client.IgnoreNotFound(err) != nil {
				return err
			}
		}
	}
	return nil
}

// Ensures that the given federated resource is the owner of the given resource, by checking that the owner annotation on the resource matches the federated resource.
func (f *federatedGatewayReconciler) verifyOwner(fedResource *fed_gateway_solo_io_v1.FederatedGateway, resource gateway_solo_io_v1.Gateway) bool {
	fedResourceId := federation.GetIdentifier(fedResource)
	// Get the value of the owner annotation on the given resource.
	resourceOwner := resource.GetAnnotations()[federation.HubOwner]
	// This value may be empty (e.g. in earlier versions of Gloo Fed before we added this annotation), so in that case return true.
	// This is safe because before we added the annotation, we always persisted the entire identifier (no truncation) so as long as the label matches,
	// then it's a verified owner match.
	if resourceOwner == "" {
		return true
	}
	return resourceOwner == fedResourceId
}

type federatedMatchableHttpGatewayReconciler struct {
	ctx                            context.Context
	federatedMatchableHttpGateways fed_gateway_solo_io_v1.FederatedMatchableHttpGatewayClient
	baseClients                    gateway_solo_io_v1.MulticlusterClientset
	placementManager               placement.Manager
	clusterSet                     multicluster.ClusterSet
}

func NewFederatedMatchableHttpGatewayReconciler(
	ctx context.Context,
	federatedMatchableHttpGateways fed_gateway_solo_io_v1.FederatedMatchableHttpGatewayClient,
	baseClients gateway_solo_io_v1.MulticlusterClientset,
	placementManager placement.Manager,
	clusterSet multicluster.ClusterSet,
) controller.FederatedMatchableHttpGatewayFinalizer {
	return &federatedMatchableHttpGatewayReconciler{
		ctx:                            ctx,
		federatedMatchableHttpGateways: federatedMatchableHttpGateways,
		baseClients:                    baseClients,
		placementManager:               placementManager,
		clusterSet:                     clusterSet,
	}
}

func (f *federatedMatchableHttpGatewayReconciler) ReconcileFederatedMatchableHttpGateway(obj *fed_gateway_solo_io_v1.FederatedMatchableHttpGateway) (reconcile.Result, error) {
	currentPlacementStatus := f.placementManager.GetPlacementStatus(&obj.Status)
	needsReconcile := obj.NeedsReconcile(currentPlacementStatus)
	allClusters := f.clusterSet.ListClusters()
	contextutils.LoggerFrom(f.ctx).Debugw("ReconcileFederatedMatchableHttpGateway", zap.Any("FederatedMatchableHttpGateway", obj), zap.Any("needsReconcile", needsReconcile),
		zap.Any("allClusters", allClusters))

	if !needsReconcile {
		return reconcile.Result{}, nil
	}

	statusBuilder := f.placementManager.GetBuilder()

	// Validate resource
	if obj.Spec.GetPlacement() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.PlacementMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedMatchableHttpGateways.UpdateFederatedMatchableHttpGatewayStatus(f.ctx, obj)
	}
	for _, cluster := range obj.Spec.Placement.GetClusters() {
		if !stringutils.ContainsString(cluster, allClusters) {
			updatedPlacementStatus := statusBuilder.
				UpdateUnprocessed(currentPlacementStatus, placement.ClusterNotRegistered(cluster), mc_types.PlacementStatus_INVALID).
				Eject(obj.GetGeneration())
			f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
			return reconcile.Result{}, f.federatedMatchableHttpGateways.UpdateFederatedMatchableHttpGatewayStatus(f.ctx, obj)
		}
	}
	if obj.Spec.Template.GetSpec() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.SpecTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedMatchableHttpGateways.UpdateFederatedMatchableHttpGatewayStatus(f.ctx, obj)
	}
	if obj.Spec.Template.GetMetadata() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.MetaTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedMatchableHttpGateways.UpdateFederatedMatchableHttpGatewayStatus(f.ctx, obj)
	}

	// ownerLabel is used to reference Federated resources via their children.
	ownerLabel := federation.GetOwnerLabel(obj)
	// since ownerLabel may be truncated (max length 63), we also store the full value in an annotation
	// for verification in case of collisions
	ownerAnnotation := federation.GetOwnerAnnotation(obj)

	spec := obj.Spec.Template.GetSpec()
	meta := obj.Spec.Template.GetMetadata()
	labels := federation.Merge(meta.GetLabels(), ownerLabel)
	annotations := federation.Merge(meta.GetAnnotations(), ownerAnnotation)

	multiErr := &multierror.Error{}
	for _, cluster := range allClusters {
		clusterMatchableHttpGateways := gateway_solo_io_v1_sets.NewMatchableHttpGatewaySet()
		if stringutils.ContainsString(cluster, obj.Spec.Placement.GetClusters()) {
			for _, namespace := range obj.Spec.Placement.GetNamespaces() {

				clusterMatchableHttpGateways.Insert(&gateway_solo_io_v1.MatchableHttpGateway{
					ObjectMeta: metav1.ObjectMeta{
						Namespace:   namespace,
						Name:        meta.GetName(),
						Labels:      labels,
						Annotations: annotations,
					},
					Spec: *spec,
				})
			}
		}

		if err := f.ensureCluster(cluster, statusBuilder, clusterMatchableHttpGateways, obj); err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
		}
	}

	f.placementManager.SetPlacementStatus(&obj.Status, statusBuilder.Build(obj.GetGeneration()))
	err := f.federatedMatchableHttpGateways.UpdateFederatedMatchableHttpGatewayStatus(f.ctx, obj)
	if err != nil {
		multiErr.Errors = append(multiErr.Errors, err)
		contextutils.LoggerFrom(f.ctx).Errorw("Failed to update status on federated matchableHttpGateway", zap.Error(err))
	}

	return reconcile.Result{}, multiErr.ErrorOrNil()
}

func (f *federatedMatchableHttpGatewayReconciler) FederatedMatchableHttpGatewayFinalizerName() string {
	return federation.HubFinalizer
}

func (f *federatedMatchableHttpGatewayReconciler) FinalizeFederatedMatchableHttpGateway(obj *fed_gateway_solo_io_v1.FederatedMatchableHttpGateway) error {
	return f.deleteAll(obj)
}

// ensureCluster upserts all desired resources on the given cluster.
// An error is returned only if a retry is expected to resolve the issue.
func (f *federatedMatchableHttpGatewayReconciler) ensureCluster(cluster string, statusBuilder placement.StatusBuilder, desired gateway_solo_io_v1_sets.MatchableHttpGatewaySet, fedResource *fed_gateway_solo_io_v1.FederatedMatchableHttpGateway) error {
	clientset, err := f.baseClients.Cluster(cluster)
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to get clientset", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToCreateClientForCluster(cluster),
		})
		return err
	}

	matchableHttpGatewayClient := clientset.MatchableHttpGateways()

	ownerLabel := federation.GetOwnerLabel(fedResource)
	existingList, err := matchableHttpGatewayClient.ListMatchableHttpGateway(f.ctx, client.MatchingLabels(ownerLabel))
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to list MatchableHttpGateways", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToListResource("matchableHttpGateway", cluster),
		})
		return err
	}

	existing := gateway_solo_io_v1_sets.NewMatchableHttpGatewaySet()
	for _, matchableHttpGateway := range existingList.Items {
		// double-check that this MatchableHttpGateway is actually owned by this FederatedMatchableHttpGateway
		if !f.verifyOwner(fedResource, matchableHttpGateway) {
			continue
		}
		matchableHttpGatewayPointer := matchableHttpGateway
		existing.Insert(&matchableHttpGatewayPointer)
	}

	multiErr := &multierror.Error{}
	for _, desiredMatchableHttpGateway := range desired.List() {
		err := matchableHttpGatewayClient.UpsertMatchableHttpGateway(f.ctx, desiredMatchableHttpGateway)
		if err != nil && errors.IsConflict(err) {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert matchableHttpGateway due to resource conflict", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredMatchableHttpGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResourceDueToConflict("matchableHttpGateway"),
			})
		} else if err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert matchableHttpGateway", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredMatchableHttpGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResource("matchableHttpGateway"),
			})
		} else {
			statusBuilder.AddDestination(cluster, desiredMatchableHttpGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State: mc_types.PlacementStatus_PLACED,
			})
		}
	}

	for _, staleMatchableHttpGateway := range existing.Difference(desired).List() {
		err := matchableHttpGatewayClient.DeleteMatchableHttpGateway(f.ctx, client.ObjectKey{
			Namespace: staleMatchableHttpGateway.Namespace,
			Name:      staleMatchableHttpGateway.Name,
		})
		if client.IgnoreNotFound(err) != nil {
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to delete matchableHttpGateway", zap.Error(err))
			statusBuilder.AddDestination(cluster, staleMatchableHttpGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_STALE,
				Message: placement.FailedToDeleteResource("matchableHttpGateway"),
			})
		}
	}

	return multiErr.ErrorOrNil()
}

// Delete all MatchableHttpGateways managed by the given FederatedMatchableHttpGateway on all clusters.
// Used to ensure that MatchableHttpGateways generated by a FederatedMatchableHttpGateway are cleaned up on delete.
func (f *federatedMatchableHttpGatewayReconciler) deleteAll(fedResource *fed_gateway_solo_io_v1.FederatedMatchableHttpGateway) error {
	ownerLabel := federation.GetOwnerLabel(fedResource)
	for _, cluster := range f.clusterSet.ListClusters() {
		clusterClient, err := f.baseClients.Cluster(cluster)
		if err != nil {
			return err
		}
		// TODO this requires permissions in all namespaces, we could restrict to to namespaces referenced by gloo instances
		list, err := clusterClient.MatchableHttpGateways().ListMatchableHttpGateway(f.ctx, client.MatchingLabels(ownerLabel))
		if err != nil {
			return err
		}

		for _, matchableHttpGateway := range list.Items {
			// double-check that this MatchableHttpGateway is actually owned by this FederatedMatchableHttpGateway
			if !f.verifyOwner(fedResource, matchableHttpGateway) {
				continue
			}
			err = clusterClient.MatchableHttpGateways().DeleteMatchableHttpGateway(f.ctx, client.ObjectKey{
				Namespace: matchableHttpGateway.Namespace,
				Name:      matchableHttpGateway.Name,
			})
			if client.IgnoreNotFound(err) != nil {
				return err
			}
		}
	}
	return nil
}

// Ensures that the given federated resource is the owner of the given resource, by checking that the owner annotation on the resource matches the federated resource.
func (f *federatedMatchableHttpGatewayReconciler) verifyOwner(fedResource *fed_gateway_solo_io_v1.FederatedMatchableHttpGateway, resource gateway_solo_io_v1.MatchableHttpGateway) bool {
	fedResourceId := federation.GetIdentifier(fedResource)
	// Get the value of the owner annotation on the given resource.
	resourceOwner := resource.GetAnnotations()[federation.HubOwner]
	// This value may be empty (e.g. in earlier versions of Gloo Fed before we added this annotation), so in that case return true.
	// This is safe because before we added the annotation, we always persisted the entire identifier (no truncation) so as long as the label matches,
	// then it's a verified owner match.
	if resourceOwner == "" {
		return true
	}
	return resourceOwner == fedResourceId
}

type federatedMatchableTcpGatewayReconciler struct {
	ctx                           context.Context
	federatedMatchableTcpGateways fed_gateway_solo_io_v1.FederatedMatchableTcpGatewayClient
	baseClients                   gateway_solo_io_v1.MulticlusterClientset
	placementManager              placement.Manager
	clusterSet                    multicluster.ClusterSet
}

func NewFederatedMatchableTcpGatewayReconciler(
	ctx context.Context,
	federatedMatchableTcpGateways fed_gateway_solo_io_v1.FederatedMatchableTcpGatewayClient,
	baseClients gateway_solo_io_v1.MulticlusterClientset,
	placementManager placement.Manager,
	clusterSet multicluster.ClusterSet,
) controller.FederatedMatchableTcpGatewayFinalizer {
	return &federatedMatchableTcpGatewayReconciler{
		ctx:                           ctx,
		federatedMatchableTcpGateways: federatedMatchableTcpGateways,
		baseClients:                   baseClients,
		placementManager:              placementManager,
		clusterSet:                    clusterSet,
	}
}

func (f *federatedMatchableTcpGatewayReconciler) ReconcileFederatedMatchableTcpGateway(obj *fed_gateway_solo_io_v1.FederatedMatchableTcpGateway) (reconcile.Result, error) {
	currentPlacementStatus := f.placementManager.GetPlacementStatus(&obj.Status)
	needsReconcile := obj.NeedsReconcile(currentPlacementStatus)
	allClusters := f.clusterSet.ListClusters()
	contextutils.LoggerFrom(f.ctx).Debugw("ReconcileFederatedMatchableTcpGateway", zap.Any("FederatedMatchableTcpGateway", obj), zap.Any("needsReconcile", needsReconcile),
		zap.Any("allClusters", allClusters))

	if !needsReconcile {
		return reconcile.Result{}, nil
	}

	statusBuilder := f.placementManager.GetBuilder()

	// Validate resource
	if obj.Spec.GetPlacement() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.PlacementMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedMatchableTcpGateways.UpdateFederatedMatchableTcpGatewayStatus(f.ctx, obj)
	}
	for _, cluster := range obj.Spec.Placement.GetClusters() {
		if !stringutils.ContainsString(cluster, allClusters) {
			updatedPlacementStatus := statusBuilder.
				UpdateUnprocessed(currentPlacementStatus, placement.ClusterNotRegistered(cluster), mc_types.PlacementStatus_INVALID).
				Eject(obj.GetGeneration())
			f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
			return reconcile.Result{}, f.federatedMatchableTcpGateways.UpdateFederatedMatchableTcpGatewayStatus(f.ctx, obj)
		}
	}
	if obj.Spec.Template.GetSpec() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.SpecTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedMatchableTcpGateways.UpdateFederatedMatchableTcpGatewayStatus(f.ctx, obj)
	}
	if obj.Spec.Template.GetMetadata() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.MetaTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedMatchableTcpGateways.UpdateFederatedMatchableTcpGatewayStatus(f.ctx, obj)
	}

	// ownerLabel is used to reference Federated resources via their children.
	ownerLabel := federation.GetOwnerLabel(obj)
	// since ownerLabel may be truncated (max length 63), we also store the full value in an annotation
	// for verification in case of collisions
	ownerAnnotation := federation.GetOwnerAnnotation(obj)

	spec := obj.Spec.Template.GetSpec()
	meta := obj.Spec.Template.GetMetadata()
	labels := federation.Merge(meta.GetLabels(), ownerLabel)
	annotations := federation.Merge(meta.GetAnnotations(), ownerAnnotation)

	multiErr := &multierror.Error{}
	for _, cluster := range allClusters {
		clusterMatchableTcpGateways := gateway_solo_io_v1_sets.NewMatchableTcpGatewaySet()
		if stringutils.ContainsString(cluster, obj.Spec.Placement.GetClusters()) {
			for _, namespace := range obj.Spec.Placement.GetNamespaces() {

				clusterMatchableTcpGateways.Insert(&gateway_solo_io_v1.MatchableTcpGateway{
					ObjectMeta: metav1.ObjectMeta{
						Namespace:   namespace,
						Name:        meta.GetName(),
						Labels:      labels,
						Annotations: annotations,
					},
					Spec: *spec,
				})
			}
		}

		if err := f.ensureCluster(cluster, statusBuilder, clusterMatchableTcpGateways, obj); err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
		}
	}

	f.placementManager.SetPlacementStatus(&obj.Status, statusBuilder.Build(obj.GetGeneration()))
	err := f.federatedMatchableTcpGateways.UpdateFederatedMatchableTcpGatewayStatus(f.ctx, obj)
	if err != nil {
		multiErr.Errors = append(multiErr.Errors, err)
		contextutils.LoggerFrom(f.ctx).Errorw("Failed to update status on federated matchableTcpGateway", zap.Error(err))
	}

	return reconcile.Result{}, multiErr.ErrorOrNil()
}

func (f *federatedMatchableTcpGatewayReconciler) FederatedMatchableTcpGatewayFinalizerName() string {
	return federation.HubFinalizer
}

func (f *federatedMatchableTcpGatewayReconciler) FinalizeFederatedMatchableTcpGateway(obj *fed_gateway_solo_io_v1.FederatedMatchableTcpGateway) error {
	return f.deleteAll(obj)
}

// ensureCluster upserts all desired resources on the given cluster.
// An error is returned only if a retry is expected to resolve the issue.
func (f *federatedMatchableTcpGatewayReconciler) ensureCluster(cluster string, statusBuilder placement.StatusBuilder, desired gateway_solo_io_v1_sets.MatchableTcpGatewaySet, fedResource *fed_gateway_solo_io_v1.FederatedMatchableTcpGateway) error {
	clientset, err := f.baseClients.Cluster(cluster)
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to get clientset", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToCreateClientForCluster(cluster),
		})
		return err
	}

	matchableTcpGatewayClient := clientset.MatchableTcpGateways()

	ownerLabel := federation.GetOwnerLabel(fedResource)
	existingList, err := matchableTcpGatewayClient.ListMatchableTcpGateway(f.ctx, client.MatchingLabels(ownerLabel))
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to list MatchableTcpGateways", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToListResource("matchableTcpGateway", cluster),
		})
		return err
	}

	existing := gateway_solo_io_v1_sets.NewMatchableTcpGatewaySet()
	for _, matchableTcpGateway := range existingList.Items {
		// double-check that this MatchableTcpGateway is actually owned by this FederatedMatchableTcpGateway
		if !f.verifyOwner(fedResource, matchableTcpGateway) {
			continue
		}
		matchableTcpGatewayPointer := matchableTcpGateway
		existing.Insert(&matchableTcpGatewayPointer)
	}

	multiErr := &multierror.Error{}
	for _, desiredMatchableTcpGateway := range desired.List() {
		err := matchableTcpGatewayClient.UpsertMatchableTcpGateway(f.ctx, desiredMatchableTcpGateway)
		if err != nil && errors.IsConflict(err) {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert matchableTcpGateway due to resource conflict", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredMatchableTcpGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResourceDueToConflict("matchableTcpGateway"),
			})
		} else if err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert matchableTcpGateway", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredMatchableTcpGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResource("matchableTcpGateway"),
			})
		} else {
			statusBuilder.AddDestination(cluster, desiredMatchableTcpGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State: mc_types.PlacementStatus_PLACED,
			})
		}
	}

	for _, staleMatchableTcpGateway := range existing.Difference(desired).List() {
		err := matchableTcpGatewayClient.DeleteMatchableTcpGateway(f.ctx, client.ObjectKey{
			Namespace: staleMatchableTcpGateway.Namespace,
			Name:      staleMatchableTcpGateway.Name,
		})
		if client.IgnoreNotFound(err) != nil {
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to delete matchableTcpGateway", zap.Error(err))
			statusBuilder.AddDestination(cluster, staleMatchableTcpGateway.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_STALE,
				Message: placement.FailedToDeleteResource("matchableTcpGateway"),
			})
		}
	}

	return multiErr.ErrorOrNil()
}

// Delete all MatchableTcpGateways managed by the given FederatedMatchableTcpGateway on all clusters.
// Used to ensure that MatchableTcpGateways generated by a FederatedMatchableTcpGateway are cleaned up on delete.
func (f *federatedMatchableTcpGatewayReconciler) deleteAll(fedResource *fed_gateway_solo_io_v1.FederatedMatchableTcpGateway) error {
	ownerLabel := federation.GetOwnerLabel(fedResource)
	for _, cluster := range f.clusterSet.ListClusters() {
		clusterClient, err := f.baseClients.Cluster(cluster)
		if err != nil {
			return err
		}
		// TODO this requires permissions in all namespaces, we could restrict to to namespaces referenced by gloo instances
		list, err := clusterClient.MatchableTcpGateways().ListMatchableTcpGateway(f.ctx, client.MatchingLabels(ownerLabel))
		if err != nil {
			return err
		}

		for _, matchableTcpGateway := range list.Items {
			// double-check that this MatchableTcpGateway is actually owned by this FederatedMatchableTcpGateway
			if !f.verifyOwner(fedResource, matchableTcpGateway) {
				continue
			}
			err = clusterClient.MatchableTcpGateways().DeleteMatchableTcpGateway(f.ctx, client.ObjectKey{
				Namespace: matchableTcpGateway.Namespace,
				Name:      matchableTcpGateway.Name,
			})
			if client.IgnoreNotFound(err) != nil {
				return err
			}
		}
	}
	return nil
}

// Ensures that the given federated resource is the owner of the given resource, by checking that the owner annotation on the resource matches the federated resource.
func (f *federatedMatchableTcpGatewayReconciler) verifyOwner(fedResource *fed_gateway_solo_io_v1.FederatedMatchableTcpGateway, resource gateway_solo_io_v1.MatchableTcpGateway) bool {
	fedResourceId := federation.GetIdentifier(fedResource)
	// Get the value of the owner annotation on the given resource.
	resourceOwner := resource.GetAnnotations()[federation.HubOwner]
	// This value may be empty (e.g. in earlier versions of Gloo Fed before we added this annotation), so in that case return true.
	// This is safe because before we added the annotation, we always persisted the entire identifier (no truncation) so as long as the label matches,
	// then it's a verified owner match.
	if resourceOwner == "" {
		return true
	}
	return resourceOwner == fedResourceId
}

type federatedVirtualServiceReconciler struct {
	ctx                      context.Context
	federatedVirtualServices fed_gateway_solo_io_v1.FederatedVirtualServiceClient
	baseClients              gateway_solo_io_v1.MulticlusterClientset
	placementManager         placement.Manager
	clusterSet               multicluster.ClusterSet
}

func NewFederatedVirtualServiceReconciler(
	ctx context.Context,
	federatedVirtualServices fed_gateway_solo_io_v1.FederatedVirtualServiceClient,
	baseClients gateway_solo_io_v1.MulticlusterClientset,
	placementManager placement.Manager,
	clusterSet multicluster.ClusterSet,
) controller.FederatedVirtualServiceFinalizer {
	return &federatedVirtualServiceReconciler{
		ctx:                      ctx,
		federatedVirtualServices: federatedVirtualServices,
		baseClients:              baseClients,
		placementManager:         placementManager,
		clusterSet:               clusterSet,
	}
}

func (f *federatedVirtualServiceReconciler) ReconcileFederatedVirtualService(obj *fed_gateway_solo_io_v1.FederatedVirtualService) (reconcile.Result, error) {
	currentPlacementStatus := f.placementManager.GetPlacementStatus(&obj.Status)
	needsReconcile := obj.NeedsReconcile(currentPlacementStatus)
	allClusters := f.clusterSet.ListClusters()
	contextutils.LoggerFrom(f.ctx).Debugw("ReconcileFederatedVirtualService", zap.Any("FederatedVirtualService", obj), zap.Any("needsReconcile", needsReconcile),
		zap.Any("allClusters", allClusters))

	if !needsReconcile {
		return reconcile.Result{}, nil
	}

	statusBuilder := f.placementManager.GetBuilder()

	// Validate resource
	if obj.Spec.GetPlacement() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.PlacementMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedVirtualServices.UpdateFederatedVirtualServiceStatus(f.ctx, obj)
	}
	for _, cluster := range obj.Spec.Placement.GetClusters() {
		if !stringutils.ContainsString(cluster, allClusters) {
			updatedPlacementStatus := statusBuilder.
				UpdateUnprocessed(currentPlacementStatus, placement.ClusterNotRegistered(cluster), mc_types.PlacementStatus_INVALID).
				Eject(obj.GetGeneration())
			f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
			return reconcile.Result{}, f.federatedVirtualServices.UpdateFederatedVirtualServiceStatus(f.ctx, obj)
		}
	}
	if obj.Spec.Template.GetSpec() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.SpecTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedVirtualServices.UpdateFederatedVirtualServiceStatus(f.ctx, obj)
	}
	if obj.Spec.Template.GetMetadata() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.MetaTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedVirtualServices.UpdateFederatedVirtualServiceStatus(f.ctx, obj)
	}

	// ownerLabel is used to reference Federated resources via their children.
	ownerLabel := federation.GetOwnerLabel(obj)
	// since ownerLabel may be truncated (max length 63), we also store the full value in an annotation
	// for verification in case of collisions
	ownerAnnotation := federation.GetOwnerAnnotation(obj)

	spec := obj.Spec.Template.GetSpec()
	meta := obj.Spec.Template.GetMetadata()
	labels := federation.Merge(meta.GetLabels(), ownerLabel)
	annotations := federation.Merge(meta.GetAnnotations(), ownerAnnotation)

	multiErr := &multierror.Error{}
	for _, cluster := range allClusters {
		clusterVirtualServices := gateway_solo_io_v1_sets.NewVirtualServiceSet()
		if stringutils.ContainsString(cluster, obj.Spec.Placement.GetClusters()) {
			for _, namespace := range obj.Spec.Placement.GetNamespaces() {

				clusterVirtualServices.Insert(&gateway_solo_io_v1.VirtualService{
					ObjectMeta: metav1.ObjectMeta{
						Namespace:   namespace,
						Name:        meta.GetName(),
						Labels:      labels,
						Annotations: annotations,
					},
					Spec: *spec,
				})
			}
		}

		if err := f.ensureCluster(cluster, statusBuilder, clusterVirtualServices, obj); err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
		}
	}

	f.placementManager.SetPlacementStatus(&obj.Status, statusBuilder.Build(obj.GetGeneration()))
	err := f.federatedVirtualServices.UpdateFederatedVirtualServiceStatus(f.ctx, obj)
	if err != nil {
		multiErr.Errors = append(multiErr.Errors, err)
		contextutils.LoggerFrom(f.ctx).Errorw("Failed to update status on federated virtualService", zap.Error(err))
	}

	return reconcile.Result{}, multiErr.ErrorOrNil()
}

func (f *federatedVirtualServiceReconciler) FederatedVirtualServiceFinalizerName() string {
	return federation.HubFinalizer
}

func (f *federatedVirtualServiceReconciler) FinalizeFederatedVirtualService(obj *fed_gateway_solo_io_v1.FederatedVirtualService) error {
	return f.deleteAll(obj)
}

// ensureCluster upserts all desired resources on the given cluster.
// An error is returned only if a retry is expected to resolve the issue.
func (f *federatedVirtualServiceReconciler) ensureCluster(cluster string, statusBuilder placement.StatusBuilder, desired gateway_solo_io_v1_sets.VirtualServiceSet, fedResource *fed_gateway_solo_io_v1.FederatedVirtualService) error {
	clientset, err := f.baseClients.Cluster(cluster)
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to get clientset", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToCreateClientForCluster(cluster),
		})
		return err
	}

	virtualServiceClient := clientset.VirtualServices()

	ownerLabel := federation.GetOwnerLabel(fedResource)
	existingList, err := virtualServiceClient.ListVirtualService(f.ctx, client.MatchingLabels(ownerLabel))
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to list VirtualServices", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToListResource("virtualService", cluster),
		})
		return err
	}

	existing := gateway_solo_io_v1_sets.NewVirtualServiceSet()
	for _, virtualService := range existingList.Items {
		// double-check that this VirtualService is actually owned by this FederatedVirtualService
		if !f.verifyOwner(fedResource, virtualService) {
			continue
		}
		virtualServicePointer := virtualService
		existing.Insert(&virtualServicePointer)
	}

	multiErr := &multierror.Error{}
	for _, desiredVirtualService := range desired.List() {
		err := virtualServiceClient.UpsertVirtualService(f.ctx, desiredVirtualService)
		if err != nil && errors.IsConflict(err) {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert virtualService due to resource conflict", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredVirtualService.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResourceDueToConflict("virtualService"),
			})
		} else if err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert virtualService", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredVirtualService.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResource("virtualService"),
			})
		} else {
			statusBuilder.AddDestination(cluster, desiredVirtualService.Namespace, mc_types.PlacementStatus_Namespace{
				State: mc_types.PlacementStatus_PLACED,
			})
		}
	}

	for _, staleVirtualService := range existing.Difference(desired).List() {
		err := virtualServiceClient.DeleteVirtualService(f.ctx, client.ObjectKey{
			Namespace: staleVirtualService.Namespace,
			Name:      staleVirtualService.Name,
		})
		if client.IgnoreNotFound(err) != nil {
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to delete virtualService", zap.Error(err))
			statusBuilder.AddDestination(cluster, staleVirtualService.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_STALE,
				Message: placement.FailedToDeleteResource("virtualService"),
			})
		}
	}

	return multiErr.ErrorOrNil()
}

// Delete all VirtualServices managed by the given FederatedVirtualService on all clusters.
// Used to ensure that VirtualServices generated by a FederatedVirtualService are cleaned up on delete.
func (f *federatedVirtualServiceReconciler) deleteAll(fedResource *fed_gateway_solo_io_v1.FederatedVirtualService) error {
	ownerLabel := federation.GetOwnerLabel(fedResource)
	for _, cluster := range f.clusterSet.ListClusters() {
		clusterClient, err := f.baseClients.Cluster(cluster)
		if err != nil {
			return err
		}
		// TODO this requires permissions in all namespaces, we could restrict to to namespaces referenced by gloo instances
		list, err := clusterClient.VirtualServices().ListVirtualService(f.ctx, client.MatchingLabels(ownerLabel))
		if err != nil {
			return err
		}

		for _, virtualService := range list.Items {
			// double-check that this VirtualService is actually owned by this FederatedVirtualService
			if !f.verifyOwner(fedResource, virtualService) {
				continue
			}
			err = clusterClient.VirtualServices().DeleteVirtualService(f.ctx, client.ObjectKey{
				Namespace: virtualService.Namespace,
				Name:      virtualService.Name,
			})
			if client.IgnoreNotFound(err) != nil {
				return err
			}
		}
	}
	return nil
}

// Ensures that the given federated resource is the owner of the given resource, by checking that the owner annotation on the resource matches the federated resource.
func (f *federatedVirtualServiceReconciler) verifyOwner(fedResource *fed_gateway_solo_io_v1.FederatedVirtualService, resource gateway_solo_io_v1.VirtualService) bool {
	fedResourceId := federation.GetIdentifier(fedResource)
	// Get the value of the owner annotation on the given resource.
	resourceOwner := resource.GetAnnotations()[federation.HubOwner]
	// This value may be empty (e.g. in earlier versions of Gloo Fed before we added this annotation), so in that case return true.
	// This is safe because before we added the annotation, we always persisted the entire identifier (no truncation) so as long as the label matches,
	// then it's a verified owner match.
	if resourceOwner == "" {
		return true
	}
	return resourceOwner == fedResourceId
}

type federatedRouteTableReconciler struct {
	ctx                  context.Context
	federatedRouteTables fed_gateway_solo_io_v1.FederatedRouteTableClient
	baseClients          gateway_solo_io_v1.MulticlusterClientset
	placementManager     placement.Manager
	clusterSet           multicluster.ClusterSet
}

func NewFederatedRouteTableReconciler(
	ctx context.Context,
	federatedRouteTables fed_gateway_solo_io_v1.FederatedRouteTableClient,
	baseClients gateway_solo_io_v1.MulticlusterClientset,
	placementManager placement.Manager,
	clusterSet multicluster.ClusterSet,
) controller.FederatedRouteTableFinalizer {
	return &federatedRouteTableReconciler{
		ctx:                  ctx,
		federatedRouteTables: federatedRouteTables,
		baseClients:          baseClients,
		placementManager:     placementManager,
		clusterSet:           clusterSet,
	}
}

func (f *federatedRouteTableReconciler) ReconcileFederatedRouteTable(obj *fed_gateway_solo_io_v1.FederatedRouteTable) (reconcile.Result, error) {
	currentPlacementStatus := f.placementManager.GetPlacementStatus(&obj.Status)
	needsReconcile := obj.NeedsReconcile(currentPlacementStatus)
	allClusters := f.clusterSet.ListClusters()
	contextutils.LoggerFrom(f.ctx).Debugw("ReconcileFederatedRouteTable", zap.Any("FederatedRouteTable", obj), zap.Any("needsReconcile", needsReconcile),
		zap.Any("allClusters", allClusters))

	if !needsReconcile {
		return reconcile.Result{}, nil
	}

	statusBuilder := f.placementManager.GetBuilder()

	// Validate resource
	if obj.Spec.GetPlacement() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.PlacementMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedRouteTables.UpdateFederatedRouteTableStatus(f.ctx, obj)
	}
	for _, cluster := range obj.Spec.Placement.GetClusters() {
		if !stringutils.ContainsString(cluster, allClusters) {
			updatedPlacementStatus := statusBuilder.
				UpdateUnprocessed(currentPlacementStatus, placement.ClusterNotRegistered(cluster), mc_types.PlacementStatus_INVALID).
				Eject(obj.GetGeneration())
			f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
			return reconcile.Result{}, f.federatedRouteTables.UpdateFederatedRouteTableStatus(f.ctx, obj)
		}
	}
	if obj.Spec.Template.GetSpec() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.SpecTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedRouteTables.UpdateFederatedRouteTableStatus(f.ctx, obj)
	}
	if obj.Spec.Template.GetMetadata() == nil {
		updatedPlacementStatus := statusBuilder.
			UpdateUnprocessed(currentPlacementStatus, placement.MetaTemplateMissing, mc_types.PlacementStatus_INVALID).
			Eject(obj.GetGeneration())
		f.placementManager.SetPlacementStatus(&obj.Status, updatedPlacementStatus)
		return reconcile.Result{}, f.federatedRouteTables.UpdateFederatedRouteTableStatus(f.ctx, obj)
	}

	// ownerLabel is used to reference Federated resources via their children.
	ownerLabel := federation.GetOwnerLabel(obj)
	// since ownerLabel may be truncated (max length 63), we also store the full value in an annotation
	// for verification in case of collisions
	ownerAnnotation := federation.GetOwnerAnnotation(obj)

	spec := obj.Spec.Template.GetSpec()
	meta := obj.Spec.Template.GetMetadata()
	labels := federation.Merge(meta.GetLabels(), ownerLabel)
	annotations := federation.Merge(meta.GetAnnotations(), ownerAnnotation)

	multiErr := &multierror.Error{}
	for _, cluster := range allClusters {
		clusterRouteTables := gateway_solo_io_v1_sets.NewRouteTableSet()
		if stringutils.ContainsString(cluster, obj.Spec.Placement.GetClusters()) {
			for _, namespace := range obj.Spec.Placement.GetNamespaces() {

				clusterRouteTables.Insert(&gateway_solo_io_v1.RouteTable{
					ObjectMeta: metav1.ObjectMeta{
						Namespace:   namespace,
						Name:        meta.GetName(),
						Labels:      labels,
						Annotations: annotations,
					},
					Spec: *spec,
				})
			}
		}

		if err := f.ensureCluster(cluster, statusBuilder, clusterRouteTables, obj); err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
		}
	}

	f.placementManager.SetPlacementStatus(&obj.Status, statusBuilder.Build(obj.GetGeneration()))
	err := f.federatedRouteTables.UpdateFederatedRouteTableStatus(f.ctx, obj)
	if err != nil {
		multiErr.Errors = append(multiErr.Errors, err)
		contextutils.LoggerFrom(f.ctx).Errorw("Failed to update status on federated routeTable", zap.Error(err))
	}

	return reconcile.Result{}, multiErr.ErrorOrNil()
}

func (f *federatedRouteTableReconciler) FederatedRouteTableFinalizerName() string {
	return federation.HubFinalizer
}

func (f *federatedRouteTableReconciler) FinalizeFederatedRouteTable(obj *fed_gateway_solo_io_v1.FederatedRouteTable) error {
	return f.deleteAll(obj)
}

// ensureCluster upserts all desired resources on the given cluster.
// An error is returned only if a retry is expected to resolve the issue.
func (f *federatedRouteTableReconciler) ensureCluster(cluster string, statusBuilder placement.StatusBuilder, desired gateway_solo_io_v1_sets.RouteTableSet, fedResource *fed_gateway_solo_io_v1.FederatedRouteTable) error {
	clientset, err := f.baseClients.Cluster(cluster)
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to get clientset", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToCreateClientForCluster(cluster),
		})
		return err
	}

	routeTableClient := clientset.RouteTables()

	ownerLabel := federation.GetOwnerLabel(fedResource)
	existingList, err := routeTableClient.ListRouteTable(f.ctx, client.MatchingLabels(ownerLabel))
	if err != nil {
		var namespaces []string
		for _, obj := range desired.List() {
			namespaces = append(namespaces, obj.GetNamespace())
		}

		contextutils.LoggerFrom(f.ctx).Errorw("Failed to list RouteTables", zap.String("cluster", cluster), zap.Error(err))
		statusBuilder.AddDestinations([]string{cluster}, namespaces, mc_types.PlacementStatus_Namespace{
			State:   mc_types.PlacementStatus_FAILED,
			Message: placement.FailedToListResource("routeTable", cluster),
		})
		return err
	}

	existing := gateway_solo_io_v1_sets.NewRouteTableSet()
	for _, routeTable := range existingList.Items {
		// double-check that this RouteTable is actually owned by this FederatedRouteTable
		if !f.verifyOwner(fedResource, routeTable) {
			continue
		}
		routeTablePointer := routeTable
		existing.Insert(&routeTablePointer)
	}

	multiErr := &multierror.Error{}
	for _, desiredRouteTable := range desired.List() {
		err := routeTableClient.UpsertRouteTable(f.ctx, desiredRouteTable)
		if err != nil && errors.IsConflict(err) {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert routeTable due to resource conflict", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredRouteTable.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResourceDueToConflict("routeTable"),
			})
		} else if err != nil {
			multiErr.Errors = append(multiErr.Errors, err)
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to upsert routeTable", zap.Error(err))
			statusBuilder.AddDestination(cluster, desiredRouteTable.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_FAILED,
				Message: placement.FailedToUpsertResource("routeTable"),
			})
		} else {
			statusBuilder.AddDestination(cluster, desiredRouteTable.Namespace, mc_types.PlacementStatus_Namespace{
				State: mc_types.PlacementStatus_PLACED,
			})
		}
	}

	for _, staleRouteTable := range existing.Difference(desired).List() {
		err := routeTableClient.DeleteRouteTable(f.ctx, client.ObjectKey{
			Namespace: staleRouteTable.Namespace,
			Name:      staleRouteTable.Name,
		})
		if client.IgnoreNotFound(err) != nil {
			contextutils.LoggerFrom(f.ctx).Errorw("Failed to delete routeTable", zap.Error(err))
			statusBuilder.AddDestination(cluster, staleRouteTable.Namespace, mc_types.PlacementStatus_Namespace{
				State:   mc_types.PlacementStatus_STALE,
				Message: placement.FailedToDeleteResource("routeTable"),
			})
		}
	}

	return multiErr.ErrorOrNil()
}

// Delete all RouteTables managed by the given FederatedRouteTable on all clusters.
// Used to ensure that RouteTables generated by a FederatedRouteTable are cleaned up on delete.
func (f *federatedRouteTableReconciler) deleteAll(fedResource *fed_gateway_solo_io_v1.FederatedRouteTable) error {
	ownerLabel := federation.GetOwnerLabel(fedResource)
	for _, cluster := range f.clusterSet.ListClusters() {
		clusterClient, err := f.baseClients.Cluster(cluster)
		if err != nil {
			return err
		}
		// TODO this requires permissions in all namespaces, we could restrict to to namespaces referenced by gloo instances
		list, err := clusterClient.RouteTables().ListRouteTable(f.ctx, client.MatchingLabels(ownerLabel))
		if err != nil {
			return err
		}

		for _, routeTable := range list.Items {
			// double-check that this RouteTable is actually owned by this FederatedRouteTable
			if !f.verifyOwner(fedResource, routeTable) {
				continue
			}
			err = clusterClient.RouteTables().DeleteRouteTable(f.ctx, client.ObjectKey{
				Namespace: routeTable.Namespace,
				Name:      routeTable.Name,
			})
			if client.IgnoreNotFound(err) != nil {
				return err
			}
		}
	}
	return nil
}

// Ensures that the given federated resource is the owner of the given resource, by checking that the owner annotation on the resource matches the federated resource.
func (f *federatedRouteTableReconciler) verifyOwner(fedResource *fed_gateway_solo_io_v1.FederatedRouteTable, resource gateway_solo_io_v1.RouteTable) bool {
	fedResourceId := federation.GetIdentifier(fedResource)
	// Get the value of the owner annotation on the given resource.
	resourceOwner := resource.GetAnnotations()[federation.HubOwner]
	// This value may be empty (e.g. in earlier versions of Gloo Fed before we added this annotation), so in that case return true.
	// This is safe because before we added the annotation, we always persisted the entire identifier (no truncation) so as long as the label matches,
	// then it's a verified owner match.
	if resourceOwner == "" {
		return true
	}
	return resourceOwner == fedResourceId
}
