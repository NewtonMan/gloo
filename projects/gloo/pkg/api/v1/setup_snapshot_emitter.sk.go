// Code generated by solo-kit. DO NOT EDIT.

package v1

import (
	"sync"
	"time"
	"fmt"
	"context"
	// "slices"

	"go.opencensus.io/stats"
	"go.opencensus.io/stats/view"
	"go.opencensus.io/tag"
	"go.uber.org/zap"

	"github.com/solo-io/solo-kit/pkg/api/v1/clients"
	"github.com/solo-io/solo-kit/pkg/errors"
	skstats "github.com/solo-io/solo-kit/pkg/stats"

	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"github.com/solo-io/gloo/projects/gloo/cli/pkg/cmd/options/contextoptions"
	"github.com/solo-io/gloo/pkg/utils/kubeutils"
	"k8s.io/client-go/kubernetes"
	// corev1 "k8s.io/api/core/v1"


	"github.com/solo-io/go-utils/contextutils"
	"github.com/solo-io/go-utils/errutils"
)

var (
	// Deprecated. See mSetupResourcesIn
	mSetupSnapshotIn = stats.Int64("setup.gloo.solo.io/emitter/snap_in", "Deprecated. Use setup.gloo.solo.io/emitter/resources_in. The number of snapshots in", "1")

	// metrics for emitter
	mSetupResourcesIn    = stats.Int64("setup.gloo.solo.io/emitter/resources_in", "The number of resource lists received on open watch channels", "1")
	mSetupSnapshotOut    = stats.Int64("setup.gloo.solo.io/emitter/snap_out", "The number of snapshots out", "1")
	mSetupSnapshotMissed = stats.Int64("setup.gloo.solo.io/emitter/snap_missed", "The number of snapshots missed", "1")

	// views for emitter
	// deprecated: see setupResourcesInView
	setupsnapshotInView = &view.View{
		Name:        "setup.gloo.solo.io/emitter/snap_in",
		Measure:     mSetupSnapshotIn,
		Description: "Deprecated. Use setup.gloo.solo.io/emitter/resources_in. The number of snapshots updates coming in.",
		Aggregation: view.Count(),
		TagKeys:     []tag.Key{},
	}

	setupResourcesInView = &view.View{
		Name:        "setup.gloo.solo.io/emitter/resources_in",
		Measure:     mSetupResourcesIn,
		Description: "The number of resource lists received on open watch channels",
		Aggregation: view.Count(),
		TagKeys: []tag.Key{
			skstats.NamespaceKey,
			skstats.ResourceKey,
		},
	}
	setupsnapshotOutView = &view.View{
		Name:        "setup.gloo.solo.io/emitter/snap_out",
		Measure:     mSetupSnapshotOut,
		Description: "The number of snapshots updates going out",
		Aggregation: view.Count(),
		TagKeys:     []tag.Key{},
	}
	setupsnapshotMissedView = &view.View{
		Name:        "setup.gloo.solo.io/emitter/snap_missed",
		Measure:     mSetupSnapshotMissed,
		Description: "The number of snapshots updates going missed. this can happen in heavy load. missed snapshot will be re-tried after a second.",
		Aggregation: view.Count(),
		TagKeys:     []tag.Key{},
	}
)

func init() {
	view.Register(
		setupsnapshotInView,
		setupsnapshotOutView,
		setupsnapshotMissedView,
		setupResourcesInView,
	)
}

type SetupSnapshotEmitter interface {
	Snapshots(watchNamespaces []string, opts clients.WatchOpts) (<-chan *SetupSnapshot, <-chan error, error)
}

type SetupEmitter interface {
	SetupSnapshotEmitter
	Register() error
	Settings() SettingsClient
}

func NewSetupEmitter(settingsClient SettingsClient) SetupEmitter {
	return NewSetupEmitterWithEmit(settingsClient, make(chan struct{}))
}

func NewSetupEmitterWithEmit(settingsClient SettingsClient, emit <-chan struct{}) SetupEmitter {
	return &setupEmitter{
		settings:  settingsClient,
		forceEmit: emit,
	}
}

type setupEmitter struct {
	forceEmit <-chan struct{}
	settings  SettingsClient
}

func (c *setupEmitter) Register() error {
	if err := c.settings.Register(); err != nil {
		return err
	}
	return nil
}

func (c *setupEmitter) Settings() SettingsClient {
	return c.settings
}

func (c *setupEmitter) Snapshots(watchNamespaces []string, opts clients.WatchOpts) (<-chan *SetupSnapshot, <-chan error, error) {

	if len(watchNamespaces) == 0 {
		watchNamespaces = []string{""}
	}

	for _, ns := range watchNamespaces {
		if ns == "" && len(watchNamespaces) > 1 {
			return nil, nil, errors.Errorf("the \"\" namespace is used to watch all namespaces. Snapshots can either be tracked for " +
				"specific namespaces or \"\" AllNamespaces, but not both.")
		}
	}

	errs := make(chan error)
	var done sync.WaitGroup
	ctx := opts.Ctx
	/* Create channel for Settings */
	type settingsListWithNamespace struct {
		list      SettingsList
		namespace string
	}
	settingsChan := make(chan settingsListWithNamespace)

	var initialSettingsList SettingsList

	currentSnapshot := SetupSnapshot{}
	settingsByNamespace := make(map[string]SettingsList)

	kubecontext := contextoptions.KubecontextFrom(ctx)

	config, _ := kubeutils.GetRestConfigWithKubeContext(kubecontext)
	config.Timeout = 0
	config.QPS = 50
	config.Burst = 100

	kubeClient, err := kubernetes.NewForConfig(config)
	if err != nil {
		return nil, nil, err
	}

	getNamespacesWithFilter := func(ctx context.Context, opts metav1.ListOptions) ([]string, error) {

		var namespaces []string
		nsList, err := kubeClient.CoreV1().Namespaces().List(ctx, opts)
		if err != nil {
			return nil, err
		}
		for _, ns := range nsList.Items {
			namespaces = append(namespaces, ns.Name)
		}
		return namespaces, nil
	}

	for _, namespace := range watchNamespaces {
		/* Setup namespaced watch for Settings */
		{
			namespaces, err := getNamespacesWithFilter(opts.Ctx, metav1.ListOptions{
				LabelSelector: "watch=this",
			})

			fmt.Println("----------------- namespaces : ", namespaces, err)

			settings, err := c.settings.List(namespace, clients.ListOpts{Ctx: opts.Ctx, Selector: opts.Selector})
			fmt.Println("len(settings) : ", len(settings))
			settings[0].WatchNamespaces = namespaces

			if err != nil {
				return nil, nil, errors.Wrapf(err, "initial Settings list")
			}
			initialSettingsList = append(initialSettingsList, settings...)
			settingsByNamespace[namespace] = settings
		}
		settingsNamespacesChan, settingsErrs, err := c.settings.Watch(namespace, opts)
		if err != nil {
			return nil, nil, errors.Wrapf(err, "starting Settings watch")
		}

		done.Add(1)
		go func(namespace string) {
			defer done.Done()
			errutils.AggregateErrs(ctx, errs, settingsErrs, namespace+"-settings")
		}(namespace)

		nsWatcher, _ := kubeClient.CoreV1().Namespaces().Watch(ctx, metav1.ListOptions{
			LabelSelector: "watch=this",
		})
		nsChan := nsWatcher.ResultChan()

		/* Initialize snapshot for Settings */
	currentSnapshot.Settings = initialSettingsList.Sort()

		/* Watch for changes and update snapshot */
		go func(namespace string) {
			for {
				select {
				case <-ctx.Done():
					return
				case <- nsChan :
					// _, ok := event.Object.(*corev1.Namespace)
					// if !ok {
					// 	fmt.Println("Failed to convert event : ", event, ok)
					// 	continue
					// }
					// fmt.Println(ns)
					// if !slices.Contains(currentSnapshot.Settings[0].WatchNamespaces, ns.Name) {
						// 	fmt.Println("-------------- Updated NS : ", currentSnapshot.Settings[0].WatchNamespaces)
						// }
						namespaces, _ := getNamespacesWithFilter(opts.Ctx, metav1.ListOptions{
							LabelSelector: "watch=this",
						})
							currentSnapshot.Settings[0].WatchNamespaces = namespaces
							fmt.Println("-------------- Updated NS : ", currentSnapshot.Settings[0].WatchNamespaces)

					select {
					case settingsChan <- settingsListWithNamespace{list: currentSnapshot.Settings, namespace: namespace}:
					}
				case settingsList, ok := <-settingsNamespacesChan:
					if !ok {
						return
					}
					namespaces, _ := getNamespacesWithFilter(opts.Ctx, metav1.ListOptions{
						LabelSelector: "watch=this",
					})
					fmt.Println("----------------- existing namespaces : ", namespaces, err)
					settingsList[0].WatchNamespaces = namespaces
					select {
					case <-ctx.Done():
						return
					case settingsChan <- settingsListWithNamespace{list: settingsList, namespace: namespace}:
					}
				}
			}
		}(namespace)
	}

	snapshots := make(chan *SetupSnapshot)
	go func() {
		// sent initial snapshot to kick off the watch
		initialSnapshot := currentSnapshot.Clone()
		snapshots <- &initialSnapshot

		timer := time.NewTicker(time.Second * 1)
		previousHash, err := currentSnapshot.Hash(nil)
		if err != nil {
			contextutils.LoggerFrom(ctx).Panicw("error while hashing, this should never happen", zap.Error(err))
		}
		sync := func() {
			currentHash, err := currentSnapshot.Hash(nil)
			// this should never happen, so panic if it does
			if err != nil {
				contextutils.LoggerFrom(ctx).Panicw("error while hashing, this should never happen", zap.Error(err))
			}
			if previousHash == currentHash {
				return
			}

			sentSnapshot := currentSnapshot.Clone()
			select {
			case snapshots <- &sentSnapshot:
				stats.Record(ctx, mSetupSnapshotOut.M(1))
				previousHash = currentHash
			default:
				stats.Record(ctx, mSetupSnapshotMissed.M(1))
			}
		}

		defer func() {
			close(snapshots)
			// we must wait for done before closing the error chan,
			// to avoid sending on close channel.
			done.Wait()
			close(errs)
		}()
		for {
			record := func() { stats.Record(ctx, mSetupSnapshotIn.M(1)) }

			select {
			case <-timer.C:
				sync()
			case <-ctx.Done():
				return
			case <-c.forceEmit:
				sentSnapshot := currentSnapshot.Clone()
				snapshots <- &sentSnapshot
			case settingsNamespacedList, ok := <-settingsChan:
				if !ok {
					return
				}
				record()

				namespace := settingsNamespacedList.namespace

				skstats.IncrementResourceCount(
					ctx,
					namespace,
					"settings",
					mSetupResourcesIn,
				)

				// merge lists by namespace
				settingsByNamespace[namespace] = settingsNamespacedList.list
				var settingsList SettingsList
				for _, settings := range settingsByNamespace {
					settingsList = append(settingsList, settings...)
				}
				currentSnapshot.Settings = settingsList.Sort()
			}
		}
	}()
	return snapshots, errs, nil
}
